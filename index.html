<html>
	<head>
		<style type="text/css">
			body{font-family: 'Work sans' sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 24px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 18px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 22px;font-weight: bold;}
			.text{width: 95%;font-size: 16px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 16px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title" id="T1">EMOTION DETECTION FROM SPEECH</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Deepak Kumar, Roll No.: 150108008, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Harsh Sinha, Roll No.: 150108014, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Kapil Kumar, Roll No.: 150108016, Branch: EEE</p>; &nbsp; &nbsp;
				<p>Vishal Kumar Sinha, Roll No.: 150108042, Branch: EEE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading" id="T2">Abstract</div>
				<div class="text">
                                   The ability to understand the emotions in a speech is what seperates a human from a machine.
				   Emotion is one of the biggest part of a speech which truly confers the meaning of speech. Thus, With
				   the increasing mechanisation of the modern world, the human-machine interaction is one of the most looke
				   after research in today's scientific community. Our projects aim at classifying a speech into based on the
				   their emotions by extracting different features.
					

				</div>
			</div>

			<div class="section">
				<div class="heading id="T3">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					The Growing use of Machines and the necessity for a Man-Machine interaction like human
					interaction is what that have motivated the researchers to work on this project. The
					Whole idea behind the project is to develop a system through which a machine can understand 
					the emotion of a human's speech. 
					
					Emotion detection is a tool which will define the course of a new age of interdependence of 
					human and machine.
					
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading" id="T4">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						The project aims at classification of basic human emotions like sad, happy, neutral 
						and angry in a speech. The essence of project rely upon the selection of features of
						speech that was responsible for various human emotions. 
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading" id="T5">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
	
						<img src="project1.jpg" align="center" alt="Robot Hugging a Guy" width="600px" height=""/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading" id="T6">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						We have taken help of various research papers for the selection of features and further proceedings.
						One of them is the "CS239 stanford emotion detection from speech" and other one is "Survey on speech emotion 
						recognition: Features, classification schemes and databases by university of cairo"
						
						As gathered from reading various papers written on this topic, There are many features specifically
						needed for this project like LFPC, LPCC along with the common features like MFCC. There has been a lot
						of success in many areas of having a machine with emotion detection feature but there are still reasearch
						going on and researchers are bidding on achieving the man-machine interaction via speech very soon.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading" id="T7">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						We started with collecting the sample data from various sources. Then, we went on finding the particular
						features that were important and necessary for emotion detection (found after reading various research papers). We are now 
						in phase of extracting features from scratch. We have extracted some short-term features like MFCC, ZCR and others. We are 
						now on extracting LFPC, LPCC, LPC and others.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading" id="T8">1.5 Report Organization</div>
					<div class="text">
                                        <ul>
						<!-- Start edit here  -->
					 Report is orgazined in following way : <br /> <br />
						
						<li>Title and Group information<a href="#T1">[0]</a></li>
						<li> Abstract<a href="#T2">[0.1]</a></li>
                                                <li>Introduciton<a href="#T3">[1]</a></li>
						<ul>
								 <li> Introduction to problem<a href="#T4">[1.1]</a>
		                                                 <li>Figure<a href="#T5">[1.2]</a>
							         <li>Literature Review<a href="#T6">[1.3]</a>
		                                                  <li>Proposed approach<a href="#T7">[1.4]</a>
			                                          <li>Report Organization<a href="#T8">[1.5]</a></li>
						</ul>
								<li>Proposed Approach<a href="#T9">[2]</a></li>
								<ul> <li>Data Collection<a href="#T10">[2.1]</a></li>
												      <li>Preprocessing and Feature selection<a href="#T11">[2.2]</a>
						     <li>Classification<a href="#T12">[2.3]</a> 
			
						</ul>
										     <li>Experments and Results<a href="#T13">[3]</a></li>
						 <ul>
															     <li>Dataset Description<a href="#T14">[3.1]</a></li>
							<li>Discussion<a href="#T15">[3.2]</a></li>
						</ul>
						
										    <li>Conclusions<a href="#T16">[4]</a></li>
						 <ul>
							 <li> Summary<a href="#T17">[4.1]</a>
										   <li>Future Extensions<a href="#T18">[4.2]</a>
						</ul>
						
						</ul>
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading" id="T9">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					The Approach is majorly divided into three steps :
					<ol>
					            <li> Data Collection
					            <li> Preprocessing and Feature selection
					            <li>Classification
					</ol>
					<!-- Stop edit here -->
					<div class="subsection">
						<div class="heading" id="T10">2.1 Data Collection </div>
						<div class="text">
						    We have collected data from various online sources which was recorded by 
						    semi-professional actors <a href=#T14>[dataset]</a>and we have also made some data ourselves too but
						    major training data is the online one.
						</div>
					</div>
					<div class="subsection">
						<div class="heading" id="T11">2.2 Preprocessing and Feature selection</div>
						<div class="text">
							Preprocessing of data was done by mean normalization.
							We used brute force in determining the combination of features
							which gave maximum accuracy. 
						</div>
					</div>
					<div class="subsection">
						<div class="heading" id="T12">2.3 Classification</div>
						<div class="text">
							likh dena
						</div>
						
					</div>
				     
				</div>
			</div>

			<div class="section">
				<div class="heading" id="T13">3. Experiments &amp; Results</div>
				<div class="subsection">

					<div class="heading" id="T14">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						We used two datasets.<br>
						<b>Toronto emotional speech set (TESS) collection</b> was used.
						Target words were spoken in the carrier phrase "Say the word _____' by an 
						actress aged 26 and recordings were made of the set portraying each of three emotions 
						(anger, happiness and sadness).<br>.Actress speaks English as her first language and has
						musical	training.<br>
                                                Authors: Kate Dupuis, M. Kathleen Pichora-Fuller
                                                University of Toronto, Psychology Department, 2010.

						<a href="https://tspace.library.utoronto.ca/handle/1807/24487" target="#">Dataset1</a>
						<br>Another dataset we used was <b>Fullon Emotional Speech Synthesis collection</b>.
						<a href="http://homepages.inf.ed.ac.uk/ghofer/" target="#">Dataset2</a>
						<br>We recorded some of our own samples. <b>@harsh blah blah blah.</b>

						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading" id="T15">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading" id="T16">4. Conclusions</div>
				<div class="subsection">
					<div class="heading" id="T17">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						The aim of our project was to classify emotions from speech. We started out with data collection from various sources.
						We tried some online datasets which are mentioned and we have tried collecting some datasets ourselves too. After the
						Data collection, we went for pre-processing and feature selection. Pre-processing 
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading" id="T18">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						
						We have extracted very basic features in the this project due to time-constraint. So, we are thinking of extracting
						some more features like LFPC and Formants and then implement it. This project was a single level classification where
						we were finding a single emotion in one clip of sound. We have thought of extending it further and build a multi-level
						classification system, where a clip will be classified into different emotions content which it will contain.
						
						We have worked a bit and build a multi-label KNN for this.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
